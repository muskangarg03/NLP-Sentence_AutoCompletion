{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yIJHXenGh_2W"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from collections import defaultdict\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrNi0Rp-iBFn",
        "outputId": "8ea07a5b-4cf1-4df1-8e7d-1028cb6812a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download NLTK data\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UdPRA4dhiH6R"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Function to train the n-gram language model\n",
        "def train_ngram_model(corpus, n):\n",
        "    model = defaultdict(lambda: defaultdict(int))\n",
        "    for sentence in corpus:\n",
        "        tokens = ['<s>'] * (n - 1) + word_tokenize(sentence.lower()) + ['</s>']\n",
        "        for i in range(len(tokens) - n + 1):\n",
        "            context = tuple(tokens[i:i + n - 1])\n",
        "            next_word = tokens[i + n - 1]\n",
        "            model[context][next_word] += 1\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wfVwwnb8iKxM"
      },
      "outputs": [],
      "source": [
        "# Function to predict the next words given a context\n",
        "def predict_next_words(model, context):\n",
        "    if context in model:\n",
        "        return list(model[context].keys())\n",
        "    else:\n",
        "        return []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RHl7_QbMiNW3"
      },
      "outputs": [],
      "source": [
        "# Function to autocomplete a sentence\n",
        "def autocomplete_sentence(model, n, sentence, max_words=5):\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    context = tokens[-(n - 1):]\n",
        "    for _ in range(max_words):\n",
        "        next_words = predict_next_words(model, tuple(context))\n",
        "        if not next_words or '</s>' in next_words:\n",
        "            break\n",
        "        next_word = next_words[0]  # Select the first word as the prediction\n",
        "        sentence += ' ' + next_word\n",
        "        context = context[1:] + [next_word]\n",
        "    return sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ILsupOdyiQJd"
      },
      "outputs": [],
      "source": [
        "# Load Reuters corpus for training\n",
        "reuters_corpus = reuters.sents()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c8mgbB1aiTEp"
      },
      "outputs": [],
      "source": [
        "# Train a trigram model\n",
        "n = 5\n",
        "reuters_sentences = [' '.join(sentence) for sentence in reuters_corpus]\n",
        "model = train_ngram_model(reuters_sentences, n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8FXZZBhDrPRK"
      },
      "outputs": [],
      "source": [
        "# Test the autocomplete feature\n",
        "input_sentence = \"The picture is very\"\n",
        "# completed_sentence = autocomplete_sentence(model, n, input_sentence)\n",
        "# print(\"Autocompleted Sentence:\", completed_sentence)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eWWwhcZxr-_M"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Get suggestions for the next word\n",
        "context = input_sentence.split()[-(n - 1):]\n",
        "suggestions = predict_next_words(model, tuple(context))\n",
        "#print(\"Suggested words:\", suggestions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut63QL3PMj0U"
      },
      "outputs": [],
      "source": [
        "!pip install dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJZmWSdOTqDL",
        "outputId": "c19fe849-5223-4931-fd22-03c4e1de03b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model pickled successfully.\n"
          ]
        }
      ],
      "source": [
        "import dill as pickle\n",
        "\n",
        "# File path to save the pickled model\n",
        "model_file_path = \"ngram_model.pkl\"\n",
        "\n",
        "# Pickle the model\n",
        "with open(model_file_path, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        "print(\"Model pickled successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEDltdEntZMG",
        "outputId": "900b48f1-a955-451e-ddc1-3fccd8665591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Select a word from suggestions:\n",
            "1. important\n",
            "2. helpful\n",
            "3. management\n",
            "4. healthy\n",
            "5. difficult\n",
            "6. much\n",
            "7. fair\n",
            "8. low\n",
            "9. bad\n",
            "10. vulnerable\n",
            "11. light\n",
            "12. strong\n",
            "13. close\n",
            "14. interesting\n",
            "15. optimistic\n",
            "16. sensitive\n",
            "17. unstable\n",
            "18. far\n",
            "19. pleased\n",
            "20. strained\n",
            "Enter the number corresponding to your choice: 14\n",
            "Autocompleted Sentence with selected word: The picture is very interesting new approach of vice president\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Provide option to select a word from suggestions and autocomplete the sentence\n",
        "if suggestions:\n",
        "    print(\"Select a word from suggestions:\")\n",
        "    for i, word in enumerate(suggestions):\n",
        "        print(f\"{i+1}. {word}\")\n",
        "\n",
        "    # Ensure the user's input is valid\n",
        "    while True:\n",
        "        choice = input(\"Enter the number corresponding to your choice: \")\n",
        "        if choice.isdigit() and 1 <= int(choice) <= len(suggestions):\n",
        "            choice = int(choice)\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input. Please enter a number corresponding to your choice.\")\n",
        "\n",
        "    selected_word = suggestions[choice - 1]\n",
        "    completed_sentence =input_sentence+ \" \" + selected_word  # Append the selected word to the completed sentence\n",
        "\n",
        "    # Autocomplete the sentence based on the updated completed sentence\n",
        "    answer_sentence = autocomplete_sentence(model, n, completed_sentence)\n",
        "    print(\"Autocompleted Sentence with selected word:\", answer_sentence)\n",
        "else:\n",
        "    print(\"No suggestions available.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "M3fJzHRMr_B_"
      },
      "outputs": [],
      "source": [
        "# Load the pickled model\n",
        "model_file_path = \"ngram_model.pkl\"\n",
        "with open(model_file_path, 'rb') as f:\n",
        "    model = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohHv1ztrr_El",
        "outputId": "5645ca31-abbc-496f-b111-25efc33c6c1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autocompleted Sentence: The picture is very fair and open its farm products\n",
            "Suggested words: ['and']\n",
            "Select a word from suggestions:\n",
            "1. and\n",
            "Enter the number corresponding to your choice: hello my\n",
            "Invalid input. Please enter a number corresponding to your choice.\n",
            "Enter the number corresponding to your choice: 1\n",
            "Autocompleted Sentence with selected word: The picture is very fair and open its farm products market\n"
          ]
        }
      ],
      "source": [
        "# Test the unpickled model\n",
        "input_sentence = \"The picture is very fair\"\n",
        "completed_sentence = autocomplete_sentence(model, n, input_sentence)\n",
        "print(\"Autocompleted Sentence:\", completed_sentence)\n",
        "\n",
        "# Get suggestions for the next word\n",
        "context = input_sentence.split()[-(n - 1):]\n",
        "suggestions = predict_next_words(model, tuple(context))\n",
        "print(\"Suggested words:\", suggestions)\n",
        "\n",
        "# Provide option to select a word from suggestions and autocomplete the sentence\n",
        "if suggestions:\n",
        "    print(\"Select a word from suggestions:\")\n",
        "    for i, word in enumerate(suggestions):\n",
        "        print(f\"{i+1}. {word}\")\n",
        "\n",
        "    # Ensure the user's input is valid\n",
        "    while True:\n",
        "        choice = input(\"Enter the number corresponding to your choice: \")\n",
        "        if choice.isdigit() and 1 <= int(choice) <= len(suggestions):\n",
        "            choice = int(choice)\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input. Please enter a number corresponding to your choice.\")\n",
        "\n",
        "    selected_word = suggestions[choice - 1]\n",
        "    completed_sentence = input_sentence + \" \" + selected_word  # Append the selected word to the completed sentence\n",
        "\n",
        "    # Autocomplete the sentence based on the updated completed sentence\n",
        "    answer_sentence = autocomplete_sentence(model, n, completed_sentence)\n",
        "    print(\"Autocompleted Sentence with selected word:\", answer_sentence)\n",
        "else:\n",
        "    print(\"No suggestions available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzOa9Mevr_Hj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MZDVlazr_Jz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huF7H-6cr_PI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQo74n9Jo4nt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0W0-NY7q4dP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YzAqW6Aq8Yb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvDNE94rq_7E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOSwDHKCq_-r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A17TiXaNrAE0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgWoYtNMrAHd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MCseTQ5rAKx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "hsVlB23ciVKC",
        "outputId": "7b6bb81a-f640-494b-a8dd-3f92c041594e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "ename": "PicklingError",
          "evalue": "Can't pickle <function <lambda> at 0x7dbe58aac430>: attribute lookup <lambda> on __main__ failed",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f24c63e73baf>\u001b[0m in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Save the trained model to a pickle file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ngram_model.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Load the trained model from the pickle file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x7dbe58aac430>: attribute lookup <lambda> on __main__ failed"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_56mjyiq_R0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7pueRUeq-c-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUbPT6aEq-gk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USPjhh_zq-qF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2CpXTRHq-th"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgVVnlHZjBmB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
